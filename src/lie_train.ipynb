{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Wkg8HnGxcO69"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2  \n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.optimizers import RMSprop,SGD,Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pickle\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usEyCgvMnuFL",
        "outputId": "5eedeb9d-cd48-444c-bf5a-4d3e0776dbec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive', force_remount=True) \n",
        "path = '/content/drive/My Drive/Colab Notebooks/491/' "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAhUoZVdDace"
      },
      "source": [
        "#LIE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVHfpRcGHiRo"
      },
      "outputs": [],
      "source": [
        "!pip uninstall scikit-learn\n",
        "!pip install scikit-learn==0.20.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecoSroRMxazS"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "from sklearn import tree\n",
        "from sklearn import svm\n",
        "from sklearn import datasets\n",
        "from sklearn.tree import tree\n",
        "from sklearn.externals import joblib\n",
        "loaded_model = joblib.load(path + 'DT_ML_model(Microexpressions).pkl' )\n",
        "from scipy.io import wavfile\n",
        "\n",
        "samplerate, data = wavfile.read(path + 'trial_lie_001.mp4')\n",
        "\n",
        "loaded_model.predict(data)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ii_sxBIJBn2Z"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/tyiannak/pyAudioAnalysis.git\n",
        "!pip install -r ./requirements.txt\n",
        "!pip install -e "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Sz1e-myFZPV"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "from sklearn import datasets\n",
        "import librosa\n",
        "import librosa.display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w0LaKcxSFUkO"
      },
      "outputs": [],
      "source": [
        "def mp3tomfcc(file_path, max_pad):\n",
        "  audio, sample_rate = librosa.core.load(file_path)\n",
        "  mfcc = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=20)\n",
        "  pad_width = max_pad - mfcc.shape[1]\n",
        "  if (pad_width > 0):\n",
        "    mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "  else:\n",
        "    mfcc = mfcc[:,0:max_pad]\n",
        "  return mfcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPyEF0J5fOME",
        "outputId": "efee273a-e746-45bd-c176-23159c32742f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "trial_lie_040.mp4.wav\n",
            "2\n",
            "trial_lie_055.mp4.wav\n",
            "3\n",
            "trial_lie_042.mp4.wav\n",
            "4\n",
            "trial_lie_043.mp4.wav\n",
            "5\n",
            "trial_lie_054.mp4.wav\n",
            "6\n",
            "trial_lie_041.mp4.wav\n",
            "7\n",
            "trial_lie_056.mp4.wav\n",
            "8\n",
            "trial_lie_047.mp4.wav\n",
            "9\n",
            "trial_lie_051.mp4.wav\n",
            "10\n",
            "trial_lie_046.mp4.wav\n",
            "11\n",
            "trial_lie_044.mp4.wav\n",
            "12\n",
            "trial_lie_050.mp4.wav\n",
            "13\n",
            "trial_lie_053.mp4.wav\n",
            "14\n",
            "trial_lie_045.mp4.wav\n",
            "15\n",
            "trial_lie_057.mp4.wav\n",
            "16\n",
            "trial_lie_022.mp4.wav\n",
            "17\n",
            "trial_lie_052.mp4.wav\n",
            "18\n",
            "trial_lie_036.mp4.wav\n",
            "19\n",
            "trial_lie_021.mp4.wav\n",
            "20\n",
            "trial_lie_023.mp4.wav\n",
            "21\n",
            "trial_lie_037.mp4.wav\n",
            "22\n",
            "trial_lie_009.mp4.wav\n",
            "23\n",
            "trial_lie_008.mp4.wav\n",
            "24\n",
            "trial_lie_035.mp4.wav\n",
            "25\n",
            "trial_lie_034.mp4.wav\n",
            "26\n",
            "trial_lie_024.mp4.wav\n",
            "27\n",
            "trial_lie_020.mp4.wav\n",
            "28\n",
            "trial_lie_031.mp4.wav\n",
            "29\n",
            "trial_lie_030.mp4.wav\n",
            "30\n",
            "trial_lie_018.mp4.wav\n",
            "31\n",
            "trial_lie_025.mp4.wav\n",
            "32\n",
            "trial_lie_027.mp4.wav\n",
            "33\n",
            "trial_lie_017.mp4.wav\n",
            "34\n",
            "trial_lie_032.mp4.wav\n",
            "35\n",
            "trial_lie_019.mp4.wav\n",
            "36\n",
            "trial_lie_003.mp4.wav\n",
            "37\n",
            "trial_lie_033.mp4.wav\n",
            "38\n",
            "trial_lie_026.mp4.wav\n",
            "39\n",
            "trial_lie_016.mp4.wav\n",
            "40\n",
            "trial_lie_015.mp4.wav\n",
            "41\n",
            "trial_lie_014.mp4.wav\n",
            "42\n",
            "trial_lie_029.mp4.wav\n",
            "43\n",
            "trial_lie_002.mp4.wav\n",
            "44\n",
            "trial_lie_001.mp4.wav\n",
            "45\n",
            "trial_lie_039.mp4.wav\n",
            "46\n",
            "trial_lie_028.mp4.wav\n",
            "47\n",
            "trial_lie_005.mp4.wav\n",
            "48\n",
            "trial_lie_012.mp4.wav\n",
            "49\n",
            "trial_lie_010.mp4.wav\n",
            "50\n",
            "trial_lie_006.mp4.wav\n",
            "51\n",
            "trial_lie_004.mp4.wav\n",
            "52\n",
            "trial_lie_013.mp4.wav\n",
            "53\n",
            "trial_lie_011.mp4.wav\n",
            "54\n",
            "trial_lie_038.mp4.wav\n",
            "55\n",
            "trial_lie_048.mp4.wav\n",
            "56\n",
            "trial_lie_007.mp4.wav\n",
            "57\n",
            "trial_lie_059.mp4.wav\n",
            "58\n",
            "trial_lie_060.mp4.wav\n",
            "59\n",
            "trial_lie_049.mp4.wav\n",
            "60\n",
            "trial_lie_061.mp4.wav\n",
            "61\n",
            "trial_lie_058.mp4.wav\n",
            "62\n",
            "trial_truth_056.mp4.wav\n",
            "63\n",
            "trial_truth_042.mp4.wav\n",
            "64\n",
            "trial_truth_043.mp4.wav\n",
            "65\n",
            "trial_truth_041.mp4.wav\n",
            "66\n",
            "trial_truth_054.mp4.wav\n",
            "67\n",
            "trial_truth_053.mp4.wav\n",
            "68\n",
            "trial_truth_057.mp4.wav\n",
            "69\n",
            "trial_truth_050.mp4.wav\n",
            "70\n",
            "trial_truth_051.mp4.wav\n",
            "71\n",
            "trial_truth_040.mp4.wav\n",
            "72\n",
            "trial_truth_044.mp4.wav\n",
            "73\n",
            "trial_truth_055.mp4.wav\n",
            "74\n",
            "trial_truth_045.mp4.wav\n",
            "75\n",
            "trial_truth_035.mp4.wav\n",
            "76\n",
            "trial_truth_020.mp4.wav\n",
            "77\n",
            "trial_truth_034.mp4.wav\n",
            "78\n",
            "trial_truth_008.mp4.wav\n",
            "79\n",
            "trial_truth_046.mp4.wav\n",
            "80\n",
            "trial_truth_052.mp4.wav\n",
            "81\n",
            "trial_truth_009.mp4.wav\n",
            "82\n",
            "trial_truth_021.mp4.wav\n",
            "83\n",
            "trial_truth_047.mp4.wav\n",
            "84\n",
            "trial_truth_033.mp4.wav\n",
            "85\n",
            "trial_truth_023.mp4.wav\n",
            "86\n",
            "trial_truth_032.mp4.wav\n",
            "87\n",
            "trial_truth_026.mp4.wav\n",
            "88\n",
            "trial_truth_022.mp4.wav\n",
            "89\n",
            "trial_truth_018.mp4.wav\n",
            "90\n",
            "trial_truth_037.mp4.wav\n",
            "91\n",
            "trial_truth_027.mp4.wav\n",
            "92\n",
            "trial_truth_036.mp4.wav\n",
            "93\n",
            "trial_truth_030.mp4.wav\n",
            "94\n",
            "trial_truth_025.mp4.wav\n",
            "95\n",
            "trial_truth_029.mp4.wav\n",
            "96\n",
            "trial_truth_028.mp4.wav\n",
            "97\n",
            "trial_truth_001.mp4.wav\n",
            "98\n",
            "trial_truth_024.mp4.wav\n",
            "99\n",
            "trial_truth_019.mp4.wav\n",
            "100\n",
            "trial_truth_031.mp4.wav\n",
            "101\n",
            "trial_truth_014.mp4.wav\n",
            "102\n",
            "trial_truth_017.mp4.wav\n",
            "103\n",
            "trial_truth_016.mp4.wav\n",
            "104\n",
            "trial_truth_002.mp4.wav\n",
            "105\n",
            "trial_truth_012.mp4.wav\n",
            "106\n",
            "trial_truth_007.mp4.wav\n",
            "107\n",
            "trial_truth_003.mp4.wav\n",
            "108\n",
            "trial_truth_013.mp4.wav\n",
            "109\n",
            "trial_truth_015.mp4.wav\n",
            "110\n",
            "trial_truth_006.mp4.wav\n",
            "111\n",
            "trial_truth_010.mp4.wav\n",
            "112\n",
            "trial_truth_011.mp4.wav\n",
            "113\n",
            "trial_truth_039.mp4.wav\n",
            "114\n",
            "trial_truth_005.mp4.wav\n",
            "115\n",
            "trial_truth_004.mp4.wav\n",
            "116\n",
            "trial_truth_049.mp4.wav\n",
            "117\n",
            "trial_truth_058.mp4.wav\n",
            "118\n",
            "trial_truth_038.mp4.wav\n",
            "119\n",
            "trial_truth_059.mp4.wav\n",
            "120\n",
            "trial_truth_060.mp4.wav\n",
            "121\n",
            "trial_truth_048.mp4.wav\n"
          ]
        }
      ],
      "source": [
        "mfccs = []\n",
        "labels = [] # 0 = Truth, 1 = Lie \n",
        "file_path = path + 'data/'\n",
        "index = 0\n",
        "\n",
        "for f in os.listdir(file_path):\n",
        "  if f.endswith('.wav'):\n",
        "      mfccs.append(mp3tomfcc(file_path + '/' + f, 1000)) \n",
        "      if \"lie\" in f:\n",
        "        labels.append(0)\n",
        "      elif \"truth\" in f:  \n",
        "        labels.append(1)\n",
        "      index = index + 1\n",
        "      print(index)\n",
        "      print(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUhvycTLIos-",
        "outputId": "e278fa68-4153-4139-aca8-b42d4a49ca3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(121, 20, 1000)\n"
          ]
        }
      ],
      "source": [
        "mfccs = np.asarray(mfccs)\n",
        "print(mfccs.shape)\n",
        "np.save(path+'mfccs_all_loy_no_pad1000.npy', mfccs)\n",
        "mfccs_loaded = np.load(path+'mfccs_all_loy_no_pad1000.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "F3Ezh-1SKsy3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb046b38-d81b-4ade-cba0-0ab3483856fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "print(labels)\n",
        "labels = np.asarray(labels)\n",
        "np.save(path+'labels.npy', labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FrjSGxkzKRkI"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "mfccs, labels = shuffle(mfccs, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDtUNFhFNfI5",
        "outputId": "44687faf-ed66-4df7-9725-04fe841efd80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(121, 2)\n"
          ]
        }
      ],
      "source": [
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "labels = to_categorical(labels, num_classes=None)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9dkicBqEO8Fp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import IPython.display as ipd\n",
        "import keras\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rA1ojLfbLEZb"
      },
      "outputs": [],
      "source": [
        "def get_seq_model(input_shape, num_classes):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(units=16, dropout=0.05, recurrent_dropout=0.35, return_sequences=True, input_shape=input_shape))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LSTM(units=8, dropout=0.05, recurrent_dropout=0.35, return_sequences=True))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001,decay=0.0), metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0MaTkiH-Lb9V"
      },
      "outputs": [],
      "source": [
        "dim_1 = mfccs.shape[1]\n",
        "dim_2 = mfccs.shape[2]\n",
        "channels = 1\n",
        "classes = 2\n",
        "X = mfccs\n",
        "y = labels\n",
        "input_shape = (X.shape[1], X.shape[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Wk9ZXqZTL3Gw"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression # Regression classifier\n",
        "from sklearn.tree import DecisionTreeClassifier # Decision Tree classifier\n",
        "from sklearn import svm # Support Vector Machine\n",
        "from sklearn.linear_model import SGDClassifier # Stochastic Gradient Descent Classifier\n",
        "#from sklearn.ensemble import RandomForestClassifier # Random Forest and Gradient Boosting Classifier\n",
        "#from sklearn.naive_bayes import MultinomialNB # Naive Bayes Classifier \n",
        "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix # Some metrics to check the performance of the models\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1ZGsAjKWLzHn"
      },
      "outputs": [],
      "source": [
        "Classifiers = {'LR':LogisticRegression(random_state=10,C=5,max_iter=200),\n",
        "               'DTC':DecisionTreeClassifier(random_state=10,min_samples_leaf=2),\n",
        "               #'RF':RandomForestClassifier(random_state=10,n_estimators=100,n_jobs=-1),\n",
        "               #'GBC':GradientBoostingClassifier(random_state=10,n_estimators=400,learning_rate=0.2),\n",
        "               'SGD':SGDClassifier(loss=\"hinge\", penalty=\"l2\"),\n",
        "               'SVM':svm.SVC(kernel='linear', C=0.1, probability=True)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7yXk2XTNOSZ",
        "outputId": "a3beb429-1741-47a4-e64c-a05e2147cea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(84, 20000)\n",
            "(84,)\n"
          ]
        }
      ],
      "source": [
        "nsamples, nx, ny = X.shape\n",
        "X_final = X.reshape((nsamples,nx*ny))\n",
        "y_final = np.argmax(y, axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.3, random_state=1)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HrIUA9M5OSLe"
      },
      "outputs": [],
      "source": [
        "def print_stats(y_test, pred):\n",
        "    CM = confusion_matrix(y_test,pred)\n",
        "    TN, FP, FN, TP = confusion_matrix(y_test, pred).ravel()\n",
        "\n",
        "    Accuracy = accuracy_score(y_test,pred)\n",
        "    Precision = TP / (TP + FP)\n",
        "    Recall = TP / (TP + FN)\n",
        "    F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
        "\n",
        "    print('==='*20)\n",
        "    print('Accuracy = '+str(Accuracy))\n",
        "    print('==='*20) \n",
        "    print('Precision = '+str(Precision))\n",
        "    print('==='*20) \n",
        "    print('Recall = '+str(Recall))\n",
        "    print('==='*20) \n",
        "    print('F1 = '+str(F1))\n",
        "    print('==='*20) \n",
        "    print(CM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BF2YHF6AOOPn"
      },
      "outputs": [],
      "source": [
        "def ML_Pipeline(clf_name):\n",
        "    clf = Classifiers[clf_name]\n",
        "    fit = clf.fit(X_train, y_train)\n",
        "\n",
        "    #filename = 'LR_model.pkl'\n",
        "    #pickle.dump(clf, open(path+'models/'+filename, 'wb'))\n",
        "\n",
        "    predi = clf.predict(X_test)\n",
        "    \n",
        "    np.asarray(predi)\n",
        "    #np.save('MFCC_'+clf_name, predi)\n",
        "    print_stats(y_test, predi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYLHSOlLOXh-",
        "outputId": "7a4f2fef-b96c-44aa-defd-0e2dc22f1b6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Accuracy = 0.6216216216216216\n",
            "============================================================\n",
            "Precision = 0.6666666666666666\n",
            "============================================================\n",
            "Recall = 0.13333333333333333\n",
            "============================================================\n",
            "F1 = 0.2222222222222222\n",
            "============================================================\n",
            "[[21  1]\n",
            " [13  2]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/base.py:283: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  indices = (scores > 0).astype(np.int)\n"
          ]
        }
      ],
      "source": [
        "ML_Pipeline('SGD')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGIFpWcJWcf3",
        "outputId": "7871a1d4-ffff-4bc4-c196-63a7b3e62677"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 20, 16)            65088     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 20, 16)           64        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 20, 8)             800       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 160)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 322       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66,274\n",
            "Trainable params: 66,242\n",
            "Non-trainable params: 32\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "gPwMEZHrOxA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "479e2438-ca38-442c-8bc1-e92ba98f782e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(84, 20, 1000)\n",
            "(84, 2)\n",
            "Epoch 1/15\n",
            "4/4 [==============================] - 7s 266ms/step - loss: 0.6897 - accuracy: 0.5075 - val_loss: 0.7070 - val_accuracy: 0.5294\n",
            "Epoch 2/15\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.6651 - accuracy: 0.5970 - val_loss: 0.6996 - val_accuracy: 0.4706\n",
            "Epoch 3/15\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.6212 - accuracy: 0.8209 - val_loss: 0.7021 - val_accuracy: 0.4706\n",
            "Epoch 4/15\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.5929 - accuracy: 0.8955 - val_loss: 0.7009 - val_accuracy: 0.4706\n",
            "Epoch 5/15\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.5897 - accuracy: 0.8209 - val_loss: 0.7102 - val_accuracy: 0.5294\n",
            "Epoch 6/15\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.5559 - accuracy: 0.8507 - val_loss: 0.7083 - val_accuracy: 0.5294\n",
            "Epoch 7/15\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 0.5253 - accuracy: 0.9254 - val_loss: 0.7080 - val_accuracy: 0.5294\n",
            "Epoch 8/15\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.4946 - accuracy: 0.9552 - val_loss: 0.7185 - val_accuracy: 0.4118\n",
            "Epoch 9/15\n",
            "4/4 [==============================] - 0s 68ms/step - loss: 0.4514 - accuracy: 0.9552 - val_loss: 0.7327 - val_accuracy: 0.3529\n",
            "Epoch 10/15\n",
            "4/4 [==============================] - 0s 68ms/step - loss: 0.4424 - accuracy: 0.9701 - val_loss: 0.7444 - val_accuracy: 0.4118\n",
            "Epoch 11/15\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.3928 - accuracy: 0.9701 - val_loss: 0.7744 - val_accuracy: 0.3529\n",
            "Epoch 12/15\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.3689 - accuracy: 0.9254 - val_loss: 0.7164 - val_accuracy: 0.4706\n",
            "Epoch 13/15\n",
            "4/4 [==============================] - 0s 68ms/step - loss: 0.3527 - accuracy: 0.9701 - val_loss: 0.7614 - val_accuracy: 0.4706\n",
            "Epoch 14/15\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.3220 - accuracy: 0.9701 - val_loss: 0.7670 - val_accuracy: 0.4706\n",
            "Epoch 15/15\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.2895 - accuracy: 0.9552 - val_loss: 0.7898 - val_accuracy: 0.4706\n"
          ]
        }
      ],
      "source": [
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "model = get_seq_model(input_shape, classes)\n",
        "print(X_train2.shape)\n",
        "print(y_train2.shape)\n",
        "\n",
        "history = model.fit(X_train2, y_train2, batch_size=20, epochs=15, verbose=1, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqAX2iTCjwrX",
        "outputId": "4a07ba02-4b29-4b9f-ce6e-b404c83331e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://e30b9292-cfdc-47bc-9a43-dd661e1a1e49/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://e30b9292-cfdc-47bc-9a43-dd661e1a1e49/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fe50a9f4a50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fe50682f4d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "filename = 'NN_model.pkl'\n",
        "pickle.dump(history, open(path+'models/'+filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4m5jRTJPiEu",
        "outputId": "f3363d83-80ab-4a95-b77c-3451516b268c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss', 'accuracy']\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.6086 - accuracy: 0.6757\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6085554361343384, 0.6756756901741028]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "print(model.metrics_names)\n",
        "#model.evaluate(X_train2, y_train2, batch_size = 3, verbose = 1)\n",
        "model.evaluate(X_test2, y_test2, batch_size = 3, verbose = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhP6pkUNRc88",
        "outputId": "d5a77f02-1269-4a1d-bf4c-8d1e6396fb0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1.\n",
            " 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0.]\n",
            "============================================================\n",
            "Accuracy = 0.6756756756756757\n",
            "============================================================\n",
            "Precision = 0.6\n",
            "============================================================\n",
            "Recall = 0.6\n",
            "============================================================\n",
            "F1 = 0.6\n",
            "============================================================\n",
            "[[16  6]\n",
            " [ 6  9]]\n"
          ]
        }
      ],
      "source": [
        "pred = model.predict(X_test2)\n",
        "pred_int = np.zeros(pred.shape[0])\n",
        "y_test2_int = np.zeros( y_test2.shape[0])\n",
        "cnt = 0\n",
        "for i in pred:\n",
        "  if i[0] > i[1]:\n",
        "    pred_int[cnt] = 0\n",
        "  else:\n",
        "    pred_int[cnt] = 1\n",
        "  cnt += 1 \n",
        "cnt = 0\n",
        "for i in y_test2:\n",
        "  if i[0] > i[1]:\n",
        "    y_test2_int[cnt] = 0\n",
        "  else:\n",
        "    y_test2_int[cnt] = 1\n",
        "  cnt += 1  \n",
        "print(y_test2_int)    \n",
        "print_stats(y_test2_int, pred_int)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}